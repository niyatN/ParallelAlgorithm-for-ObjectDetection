{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://niyatpatel:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import numpy\n",
    "import scipy\n",
    "from scipy.misc import imread\n",
    "import pickle\n",
    "# import random\n",
    "import os\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sparkpickle\n",
    "from io import BytesIO\n",
    "import time\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction from a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(image_path, vector_size=128):\n",
    "    image = imread(image_path, mode=\"RGB\")\n",
    "    try:\n",
    "        alg = cv2.KAZE_create()\n",
    "        kps = alg.detect(image)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        needed_size = (vector_size * 64)\n",
    "        if(dsc.size < needed_size):\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print('Error: ', e)\n",
    "        return None\n",
    "    return dsc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction from batch of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_extractor(img_path):\n",
    "    files = [os.path.join(img_path, p) for p in sorted(os.listdir(img_path))]\n",
    "        \n",
    "    result = []\n",
    "    for f in files:\n",
    "        print(\"%s\" %f)\n",
    "        name = f.split('/')[-2].lower()\n",
    "        print(name)\n",
    "        features = extract_features(f)\n",
    "        print(features)\n",
    "        result.append(features)\n",
    "        dump_file_name = \"./db_dump/\"+name+\".pkl\"\n",
    "#     joblib.dump(result, dump_file_name)\n",
    "    outfile = open(dump_file_name,'wb')\n",
    "    pickle.dump(result, outfile)\n",
    "    outfile.close()\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From extracing and storing pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# folder_path='./image'\n",
    "# files = [os.path.join(folder_path, p) for p in sorted(os.listdir(folder_path))]\n",
    "# for i in files:\n",
    "#     print(i)\n",
    "#     batch_extractor(i)\n",
    "\n",
    "# batch_extractor('./image/pond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Matcher(object):\n",
    "    \n",
    "    def __init__(self,db_dump= './db_dump',vector_size=128 ):\n",
    "        self.db_dump = db_dump\n",
    "        self.vector_size = vector_size\n",
    "\n",
    "    def extract_features(self,image_path):\n",
    "        image = imread(image_path, mode=\"RGB\")\n",
    "        try:\n",
    "#             alg = cv2.xfeatures2d.SURF_create()\n",
    "            alg = cv2.KAZE_create()\n",
    "            kps = alg.detect(image)\n",
    "            kps = sorted(kps, key=lambda x: -x.response)[:self.vector_size]\n",
    "            kps, dsc = alg.compute(image, kps)\n",
    "            dsc = dsc.flatten()\n",
    "            needed_size = (self.vector_size * 64)\n",
    "            if(dsc.size < needed_size):\n",
    "                dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "        except cv2.error as e:\n",
    "            print('Error: ', e)\n",
    "            return None\n",
    "        return dsc\n",
    "\n",
    "        \n",
    "    def match(self, image_path):\n",
    "        files = [os.path.join(self.db_dump, p) for p in sorted(os.listdir(self.db_dump))]\n",
    "        features = self.extract_features(image_path)\n",
    "        print(features)\n",
    "        self.dist = {}\n",
    "        for i in files:\n",
    "#             pkl = joblib.load(i)\n",
    "            pkl_file = open(i,'rb')\n",
    "            pkl = pickle.load(pkl_file)\n",
    "#             print(pkl)\n",
    "#             print(pkl)\n",
    "#             pkl_file = sc.binaryFiles(i)\n",
    "#             pkl = pkl_file.values()\n",
    "#             print(pkl)\n",
    "#             print(pkl.take(1))\n",
    "#             print(pkl.first())\n",
    "#             pkl = np.asarray(pkl.first())\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            img_dist = scipy.spatial.distance.cdist(pkl, features.reshape(1,-1), 'euclidean').reshape(-1)\n",
    "            name = i.split('/')[-1].lower()\n",
    "            name = name.split('.')[0]\n",
    "            self.dist[name] = min(img_dist)\n",
    "            pkl_file.close()\n",
    "        print(self.dist)\n",
    "        return self.dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08858097  0.03786298  0.09164749 ...  0.0316714   0.05101985\n",
      "  0.03982824]\n",
      "{'fruit': 0.0, 'pond': 7.887596372197239, 'staircase': 8.042629064206457}\n",
      "time =  1.1024937629699707\n"
     ]
    }
   ],
   "source": [
    "m = Matcher()\n",
    "start = time.time()\n",
    "m.match('cut_watermelon.jpg.653x0_q80_crop-smart.jpg')\n",
    "end = time.time() - start\n",
    "print('time = ',end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02409058  0.05696743  0.02413429 ...  0.03673164  0.17281295\n",
      "  0.03693292]\n",
      "{'fruit': 9.621196014778496, 'pond': 8.881111575463148, 'staircase': 0.0}\n",
      "time =  0.17062854766845703\n"
     ]
    }
   ],
   "source": [
    "m = Matcher()\n",
    "start = time.time()\n",
    "m.match('./gsun_0b054a9f68b8d0ba36f620ed9e99850d.jpg')\n",
    "end = time.time() - start\n",
    "print('time = ',end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00488521  0.00223366  0.0104039  ...  0.00152859  0.03190349\n",
      "  0.06472354]\n",
      "{'fruit': 10.512500950081577, 'pond': 0.0, 'staircase': 9.983319028083455}\n",
      "time =  0.1675713062286377\n"
     ]
    }
   ],
   "source": [
    "m = Matcher()\n",
    "start = time.time()\n",
    "m.match('./gsun_0a2cc110677e3611d8b9ae97278fd489.jpg')\n",
    "end = time.time() - start\n",
    "print('time = ',end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10285926 0.15143955 0.10808402 ... 0.08395358 0.13674533 0.09273567]\n",
      "{'fruit': 0.0, 'pond': 8.867754493042764, 'staircase': 8.769415293237534}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fruit': 0.0, 'pond': 8.867754493042764, 'staircase': 8.769415293237534}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.match('water-bottle.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02653385 -0.02261907  0.09161882 ... -0.00085813  0.0057378\n",
      "  0.00831428]\n",
      "{'fruit': 8.654220710487563, 'pond': 8.17867356885083, 'staircase': 8.19352921667635}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fruit': 8.654220710487563,\n",
       " 'pond': 8.17867356885083,\n",
       " 'staircase': 8.19352921667635}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.match('foun.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_extractor('./test/img/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08028362  0.04824756  0.09115983 ...,  0.00141928  0.09569666\n",
      "  0.01787554]\n",
      "{'fruit': 8.5395672746138285, 'pond': 7.5304099914639302, 'staircase': 7.5548699058538711}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fruit': 8.5395672746138285,\n",
       " 'pond': 7.5304099914639302,\n",
       " 'staircase': 7.5548699058538711}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.match('stir.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08810823  0.03952925  0.09145768 ..., -0.0113938   0.03848445\n",
      "  0.04105413]\n",
      "{'fruit': 7.5656677237029024, 'pond': 7.9878637794427609, 'staircase': 8.0902829720718952}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fruit': 7.5656677237029024,\n",
       " 'pond': 7.9878637794427609,\n",
       " 'staircase': 8.0902829720718952}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.match('cut_watermelon.jpg.653x0_q80_crop-smart-ConvertImage.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in RDD -> 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = sc.parallelize (\n",
    "   [\"scala\", \n",
    "   \"java\", \n",
    "   \"hadoop\", \n",
    "   \"spark\", \n",
    "   \"akka\",\n",
    "   \"spark vs hadoop\", \n",
    "   \"pyspark\",\n",
    "   \"pyspark and spark\"]\n",
    ")\n",
    "counts = words.count()\n",
    "print(\"Number of elements in RDD -> %i\" % (counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[3] at RDD at PythonRDD.scala:53\n",
      "Key value pair -> [('scala', 1), ('java', 1), ('hadoop', 1), ('spark', 1), ('akka', 1), ('spark vs hadoop', 1), ('pyspark', 1), ('pyspark and spark', 1)]\n"
     ]
    }
   ],
   "source": [
    "words = sc.parallelize (\n",
    "   [\"scala\", \n",
    "   \"java\", \n",
    "   \"hadoop\", \n",
    "   \"spark\", \n",
    "   \"akka\",\n",
    "   \"spark vs hadoop\", \n",
    "   \"pyspark\",\n",
    "   \"pyspark and spark\"]\n",
    ")\n",
    "\n",
    "words_map = words.map(lambda x: (x, 1))\n",
    "print(words_map)\n",
    "mapping = words_map.collect()\n",
    "\n",
    "print(\"Key value pair -> %s\" % (mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 86, 129, 172]\n"
     ]
    }
   ],
   "source": [
    "words = sc.parallelize (\n",
    "   [1,2,3,4]\n",
    ")\n",
    "def f(x):\n",
    "    \n",
    "    return x*43\n",
    "fore = words.map(lambda x: f(x))\n",
    "print(fore.collect())\n",
    "\n",
    "\n",
    "# print(\"Key value pair -> %s\" % (mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words_map' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-937d935ae8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# words_map.sortByKey()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'words_map' is not defined"
     ]
    }
   ],
   "source": [
    "# words_map.max()\n",
    "# words_map.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features1(image_path, vector_size=128):\n",
    "    image = imread(image_path, mode=\"RGB\")\n",
    "    try:\n",
    "        alg = cv2.KAZE_create()\n",
    "        kps = alg.detect(image)\n",
    "        kps = sorted(kps, key=lambda x: -x.response)[:vector_size]\n",
    "        kps, dsc = alg.compute(image, kps)\n",
    "        dsc = dsc.flatten()\n",
    "        needed_size = (vector_size * 64)\n",
    "        if(dsc.size < needed_size):\n",
    "            dsc = np.concatenate([dsc, np.zeros(needed_size - dsc.size)])\n",
    "    except cv2.error as e:\n",
    "        print('Error: ', e)\n",
    "        return None\n",
    "    return dsc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features = extract_features1('./cut_watermelon.jpg.653x0_q80_crop-smart.jpg',128)\n",
    "# features = extract_features1('./staircase/gsun_0b054a9f68b8d0ba36f620ed9e99850d.jpg')\n",
    "# features = extract_features1('./image/pond/gsun_0a2cc110677e3611d8b9ae97278fd489.jpg')\n",
    "dist={}\n",
    "list2=[]\n",
    "def match1(i):\n",
    "    dist = {}\n",
    "    pkl_file = open(i,'rb')\n",
    "    pkl = pickle.load(pkl_file)\n",
    "    img_dist = scipy.spatial.distance.cdist(pkl, features.reshape(1,-1), 'euclidean').reshape(-1)\n",
    "    name = i.split('/')[-1].lower()\n",
    "    name = name.split('.')[0]\n",
    "    dist[name] = min(img_dist)\n",
    "    list2.append(min(img_dist))\n",
    "    pkl_file.close()\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fruit': 0.0}, {'pond': 7.887596372197239}, {'staircase': 8.042629064206457}]\n",
      "time = 0.05432915687561035\n"
     ]
    }
   ],
   "source": [
    "features = extract_features1('./cut_watermelon.jpg.653x0_q80_crop-smart.jpg',128)\n",
    "db_dump = './db_dump'\n",
    "start = time.time()\n",
    "files = [match1(os.path.join(db_dump, p)) for p in sorted(os.listdir(db_dump))]\n",
    "print(files)\n",
    "listt  = sc.parallelize(files)\n",
    "# yu = listt.map(lambda x:match1(x))\n",
    "# match1('./db_dump/img.pkl')\n",
    "a= listt.values()\n",
    "listt.collect()\n",
    "end = time.time()-start\n",
    "print('time =',end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fruit': 9.621196014778496}, {'pond': 8.881111575463148}, {'staircase': 0.0}]\n",
      "time = 0.060945749282836914\n"
     ]
    }
   ],
   "source": [
    "features = extract_features1('./gsun_0b054a9f68b8d0ba36f620ed9e99850d.jpg')\n",
    "db_dump = './db_dump'\n",
    "start = time.time()\n",
    "files = [match1(os.path.join(db_dump, p)) for p in sorted(os.listdir(db_dump))]\n",
    "print(files)\n",
    "listt  = sc.parallelize(files)\n",
    "# yu = listt.map(lambda x:match1(x))\n",
    "# match1('./db_dump/img.pkl')\n",
    "a= listt.values()\n",
    "listt.collect()\n",
    "end = time.time()-start\n",
    "print('time =',end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fruit': 10.512500950081577}, {'pond': 0.0}, {'staircase': 9.983319028083455}]\n",
      "time = 0.07507157325744629\n"
     ]
    }
   ],
   "source": [
    "features = extract_features1('./gsun_0a2cc110677e3611d8b9ae97278fd489.jpg')\n",
    "db_dump = './db_dump'\n",
    "start = time.time()\n",
    "files = [match1(os.path.join(db_dump, p)) for p in sorted(os.listdir(db_dump))]\n",
    "print(files)\n",
    "listt  = sc.parallelize(files)\n",
    "# yu = listt.map(lambda x:match1(x))\n",
    "# match1('./db_dump/img.pkl')\n",
    "a= listt.values()\n",
    "listt.collect()\n",
    "end = time.time()-start\n",
    "print('time =',end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
